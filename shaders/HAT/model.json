{
    "format": "layers-model",
    "generatedBy": "TensorFlow.js Converter v3.20.0",
    "convertedBy": "Jellyfin Upscaler Plugin",
    "version": "s",
    "modelTopology": {
        "class_name": "HAT",
        "config": [
            {
                "class_name": "Conv2D",
                "config": {
                    "filters": 180,
                    "kernel_size": [3, 3],
                    "padding": "same",
                    "activation": "linear",
                    "name": "conv_first"
                }
            },
            {
                "class_name": "HybridAttentionTransformer",
                "config": {
                    "dim": 180,
                    "depth": 6,
                    "heads": 6,
                    "window_size": 16,
                    "compress_ratio": 3,
                    "squeeze_factor": 30,
                    "conv_scale": 0.01,
                    "name": "hat_block"
                }
            },
            {
                "class_name": "Conv2D",
                "config": {
                    "filters": 180,
                    "kernel_size": [3, 3],
                    "padding": "same",
                    "activation": "linear",
                    "name": "conv_after_body"
                }
            },
            {
                "class_name": "PixelShuffleUpsampler",
                "config": {
                    "scale": 4,
                    "num_feat": 180,
                    "name": "upsampler"
                }
            },
            {
                "class_name": "Conv2D",
                "config": {
                    "filters": 3,
                    "kernel_size": [3, 3],
                    "padding": "same",
                    "activation": "linear",
                    "name": "conv_last"
                }
            }
        ]
    },
    "weightsManifest": [
        {
            "paths": ["weights.bin"],
            "weights": [
                {
                    "name": "conv_first/kernel",
                    "shape": [3, 3, 3, 180],
                    "dtype": "float32"
                },
                {
                    "name": "conv_first/bias",  
                    "shape": [180],
                    "dtype": "float32"
                },
                {
                    "name": "hat_block/norm/weight",
                    "shape": [180],
                    "dtype": "float32"
                },
                {
                    "name": "hat_block/norm/bias",
                    "shape": [180],
                    "dtype": "float32"
                },
                {
                    "name": "conv_after_body/kernel",
                    "shape": [3, 3, 180, 180],
                    "dtype": "float32"
                },
                {
                    "name": "conv_after_body/bias",
                    "shape": [180],
                    "dtype": "float32"
                },
                {
                    "name": "conv_last/kernel",
                    "shape": [3, 3, 3, 3],
                    "dtype": "float32"
                },
                {
                    "name": "conv_last/bias",
                    "shape": [3],
                    "dtype": "float32"
                }
            ]
        }
    ],
    "metadata": {
        "description": "Hybrid Attention Transformer for Image Super-Resolution",
        "architecture": "HAT",
        "scale": 4,
        "optimizedFor": ["photos", "natural-images", "high-quality"],
        "requirements": {
            "minVRAM": "6GB",
            "recommendedVRAM": "10GB", 
            "performance": "ultra-high"
        },
        "features": [
            "hybrid-attention",
            "channel-attention",
            "overlapping-cross-attention",
            "same-task-channel-attention",
            "state-of-the-art-quality"
        ],
        "benchmarks": {
            "psnr_improvement": "0.5-1.0dB over SwinIR",
            "quality_rating": "excellent"
        }
    }
}